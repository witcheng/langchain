{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ef724e",
   "metadata": {},
   "source": [
    "# Step-Back Prompting (Question-Answering)\n",
    "\n",
    "One prompting technique called \"Step-Back\" prompting can improve performance on complex questions by first asking a \"step back\" question. This can be combined with regular question-answering applications by then doing retrieval on both the original and step-back question.\n",
    "\n",
    "Read the paper [here](https://arxiv.org/abs/2310.06117)\n",
    "\n",
    "See an excellent blog post on this by Cobus Greyling [here](https://cobusgreyling.medium.com/a-new-prompt-engineering-technique-has-been-introduced-called-step-back-prompting-b00e8954cacb)\n",
    "\n",
    "In this cookbook we will replicate this technique. We modify the prompts used slightly to work better with chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67b5cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e017c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\", \n",
    "        \"output\": \"what is Jan Sindel’s personal history?\"\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "206415ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\"),\n",
    "    # Few shot examples\n",
    "    few_shot_prompt,\n",
    "    # New question\n",
    "    (\"user\", \"{question}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d643a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen = prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ba21b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"was chatgpt around while trump was president?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5992c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when was ChatGPT developed?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "32667424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "\n",
    "search = DuckDuckGoSearchAPIWrapper(max_results=4)\n",
    "\n",
    "def retriever(query):\n",
    "    return search.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffc28c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True About this rating On Jan. 30, 2023, Twitter user @echo_chamberz tweeted that the OpenAI tool ChatGPT (Chat Generative Pre-Trained Transformer) declined a request to write an AI-generated... While impressive in many respects, ChatGPT also has some major flaws. ... [President\\'s Name],\" refused to write a poem about ex-President Trump, but wrote one about President Biden ... On Wednesday, a Twitter user posted screenshots of him asking OpenAI\\'s chatbot, ChatGPT, to write a positive poem about former President Donald Trump, to which the chatbot declined, citing... During the Trump administration, Altman gained new attention as a vocal critic of the president. It was against that backdrop that he was rumored to be considering a run for California governor.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00c77443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"June 4, 2023 ⋅ 4 min read 124 SHARES 14K READS At the end of 2022, OpenAI introduced the world to ChatGPT. Since its launch, ChatGPT hasn't shown significant signs of slowing down in developing... Jace Dela Cruz, Tech Times 28 February 2023, 08:02 am Every dystopian science fiction starts with the idea that humans will be overrun by robots. 90s movies and books believed this would happen to... ChatGPT is an artificial intelligence (AI) chatbot built on top of OpenAI's foundational large language models (LLMs) like GPT-4 and its predecessors. Aleksandra Yosifova 14 Aug 2023 7 min read ChatGPT isn't the first language model; it isn't even the first GPT model. But it made a significant leap in natural language processing—popularizing large language models and accelerating the adoption of AI. What factors contributed to ChatGPT's success?\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(question_gen.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b257bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "# response_prompt = ChatPromptTemplate.from_template(response_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f48c65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "response_prompt = hub.pull(\"langchain-ai/stepback-answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97a6d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\n",
    "    # Retrieve context using the normal question\n",
    "    \"normal_context\": RunnableLambda(lambda x: x['question']) | retriever,\n",
    "    # Retrieve context using the step-back question\n",
    "    \"step_back_context\": question_gen | retriever,\n",
    "    # Pass on the question\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce554cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No, ChatGPT was not around while Donald Trump was president. ChatGPT was launched by OpenAI on November 30, 2022, which was after Donald Trump's presidency. Therefore, it would not have been available for use during his time in office.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb8dd2",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00db8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "{normal_context}\n",
    "\n",
    "Original Question: {question}\n",
    "Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06335ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\n",
    "    # Retrieve context using the normal question (only the first 3 results)\n",
    "    \"normal_context\": RunnableLambda(lambda x: x['question']) | retriever,\n",
    "    # Pass on the question\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15e0e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the given context, it is unclear whether ChatGPT was around while Trump was president. The context mentions that a Twitter user requested ChatGPT to write a positive poem about former President Donald Trump, to which the chatbot declined. However, it does not explicitly state when this incident occurred. Therefore, without further information, we cannot definitively determine whether ChatGPT was available during Trump's presidency.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9e5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
