{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ef724e",
   "metadata": {},
   "source": [
    "# Step-Back Prompting (Question-Answering)\n",
    "\n",
    "One prompting technique called \"Step-Back\" prompting can improve performance on complex questions by first asking a \"step back\" question. This can be combined with regular question-answering applications by then doing retrieval on both the original and step-back question.\n",
    "\n",
    "Read the paper [here](https://arxiv.org/abs/2310.06117)\n",
    "\n",
    "See an excellent blog post on this by Cobus Greyling [here](https://cobusgreyling.medium.com/a-new-prompt-engineering-technique-has-been-introduced-called-step-back-prompting-b00e8954cacb)\n",
    "\n",
    "In this cookbook we will replicate this technique. We modify the prompts used slightly to work better with chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67b5cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e017c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\", \n",
    "        \"output\": \"what is Jan Sindel’s personal history?\"\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206415ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\"),\n",
    "    # Few shot examples\n",
    "    few_shot_prompt,\n",
    "    # New question\n",
    "    (\"user\", \"{question}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d643a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen = prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ba21b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"was chatgpt around while trump was president?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5992c8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when was ChatGPT developed?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32667424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "\n",
    "search = DuckDuckGoSearchAPIWrapper(max_results=4)\n",
    "\n",
    "def retriever(query):\n",
    "    return search.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffc28c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True About this rating On Jan. 30, 2023, Twitter user @echo_chamberz tweeted that the OpenAI tool ChatGPT (Chat Generative Pre-Trained Transformer) declined a request to write an AI-generated... While impressive in many respects, ChatGPT also has some major flaws. ... [President\\'s Name],\" refused to write a poem about ex-President Trump, but wrote one about President Biden ... On Wednesday, a Twitter user posted screenshots of him asking OpenAI\\'s chatbot, ChatGPT, to write a positive poem about former President Donald Trump, to which the chatbot declined, citing... During the Trump administration, Altman gained new attention as a vocal critic of the president. It was against that backdrop that he was rumored to be considering a run for California governor.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00c77443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Will Douglas Heaven March 3, 2023 Stephanie Arnett/MITTR | Envato When OpenAI launched ChatGPT, with zero fanfare, in late November 2022, the San Francisco-based artificial-intelligence company... ChatGPT, which stands for Chat Generative Pre-trained Transformer, is a large language model -based chatbot developed by OpenAI and launched on November 30, 2022, which enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. The transformer architecture behind today's generation of LLMs was introduced in 2017 by a team of Google researchers. ChatGPT is an artificial intelligence (AI) chatbot built on top of OpenAI's foundational large language models (LLMs) like GPT-4 and its predecessors. This chatbot has redefined the standards of...\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(question_gen.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b257bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "# response_prompt = ChatPromptTemplate.from_template(response_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f48c65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "response_prompt = hub.pull(\"langchain-ai/stepback-answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97a6d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\n",
    "    # Retrieve context using the normal question\n",
    "    \"normal_context\": RunnableLambda(lambda x: x['question']) | retriever,\n",
    "    # Retrieve context using the step-back question\n",
    "    \"step_back_context\": question_gen | retriever,\n",
    "    # Pass on the question\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce554cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No, ChatGPT was not around while Donald Trump was president. OpenAI introduced ChatGPT at the end of 2022, which was after Trump's presidency. The context provided does not mention any specific timeline or connection between ChatGPT and Trump's presidency. Therefore, it can be concluded that ChatGPT did not exist during Trump's time in office.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb8dd2",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00db8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "{normal_context}\n",
    "\n",
    "Original Question: {question}\n",
    "Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06335ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\n",
    "    # Retrieve context using the normal question (only the first 3 results)\n",
    "    \"normal_context\": RunnableLambda(lambda x: x['question']) | retriever,\n",
    "    # Pass on the question\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15e0e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the given context, it is unclear whether ChatGPT was around while Donald Trump was president. The information provided mentions that a Twitter user posted screenshots of asking ChatGPT to write a positive poem about former President Donald Trump, to which the chatbot declined. However, it does not specify the exact timeline of when this interaction took place. Therefore, without further information, it is not possible to determine if ChatGPT was available during Trump's presidency.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
